{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a3888b",
   "metadata": {},
   "source": [
    "# Azure Synapse Database Connections\n",
    "\n",
    "This notebook demonstrates how to connect to various Azure Synapse database types:\n",
    "- **Synapse Workspace** - Management and artifact operations\n",
    "- **Synapse SQL Pools** - Dedicated and Serverless SQL databases\n",
    "- **Synapse Spark/Lake Databases** - Delta Lake and Spark metastore\n",
    "- **Linked Databases** - External linked services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f5e8a",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set your Azure Synapse workspace details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these values for your environment\n",
    "SYNAPSE_WORKSPACE_NAME = \"your-synapse-workspace\"\n",
    "SYNAPSE_SQL_ENDPOINT = f\"{SYNAPSE_WORKSPACE_NAME}.sql.azuresynapse.net\"\n",
    "SYNAPSE_DEV_ENDPOINT = f\"https://{SYNAPSE_WORKSPACE_NAME}.dev.azuresynapse.net\"\n",
    "SUBSCRIPTION_ID = \"your-subscription-id\"\n",
    "RESOURCE_GROUP = \"your-resource-group\"\n",
    "\n",
    "# Database names\n",
    "DEDICATED_SQL_POOL = \"your_dedicated_pool\"  # Dedicated SQL Pool name\n",
    "SERVERLESS_DATABASE = \"your_database\"        # Serverless SQL database\n",
    "LAKE_DATABASE = \"your_lake_db\"               # Lake database name\n",
    "\n",
    "# Azure Data Lake Storage (for Lake databases)\n",
    "ADLS_ACCOUNT = \"your_storage_account\"\n",
    "ADLS_CONTAINER = \"your_container\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c21eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Azure Government Cloud Synapse Workspace\n",
    "SYNAPSE_WORKSPACE_NAME = \"synapsedemo\"\n",
    "CLOUD_SUFFIX = \"usgovcloudapi.net\"\n",
    "\n",
    "# Endpoints from Azure Portal\n",
    "SYNAPSE_SQL_ENDPOINT = f\"synapsedemo.sql.azuresynapse.{CLOUD_SUFFIX}\"\n",
    "SYNAPSE_SERVERLESS_ENDPOINT = f\"synapsedemo-ondemand.sql.azuresynapse.{CLOUD_SUFFIX}\"\n",
    "SYNAPSE_DEV_ENDPOINT = f\"https://synapsedemo.dev.azuresynapse.{CLOUD_SUFFIX}\"\n",
    "SYNAPSE_DEDICATED_ENDPOINT = f\"synapsedemo.sql.azuresynapse.{CLOUD_SUFFIX}\"\n",
    "\n",
    "# Subscription and Resource Group\n",
    "SUBSCRIPTION_ID = \"6b71afbc-6cbe-4446-948c-3c45a4b4f160\"\n",
    "RESOURCE_GROUP = \"synapse_demo\"\n",
    "\n",
    "# Dedicated SQL Pool\n",
    "DEDICATED_SQL_POOL = \"demo_dedicated_pool\"\n",
    "\n",
    "# Lake Databases (accessed via Serverless SQL)\n",
    "LAKE_DATABASES = [\n",
    "    \"Database_all\",\n",
    "    \"default\", \n",
    "    \"demo_lake_db\",\n",
    "    \"staging_db\",\n",
    "]\n",
    "LAKE_DATABASE = \"demo_lake_db\"  # Default lake database to connect to\n",
    "\n",
    "# Serverless SQL database\n",
    "SERVERLESS_DATABASE = \"master\"\n",
    "\n",
    "# Azure Data Lake Storage (Primary ADLS Gen2 from workspace)\n",
    "ADLS_ACCOUNT = \"synapsedatalake\"\n",
    "ADLS_FILESYSTEM = \"synapsefilesystem\"\n",
    "ADLS_ENDPOINT = f\"https://{ADLS_ACCOUNT}.dfs.core.{CLOUD_SUFFIX}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d2cb1",
   "metadata": {},
   "source": [
    "## 2. Authentication Setup\n",
    "\n",
    "Using Azure Identity for authentication. This supports multiple authentication methods:\n",
    "- Azure CLI (`az login`)\n",
    "- Environment variables\n",
    "- Managed Identity (when running in Azure)\n",
    "- Interactive browser login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f11b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, AzureAuthorityHosts\n",
    "import struct\n",
    "\n",
    "# Use Azure Government Cloud authority\n",
    "AZURE_GOV_AUTHORITY = AzureAuthorityHosts.AZURE_GOVERNMENT\n",
    "\n",
    "# Use DefaultAzureCredential for flexible authentication with Azure Government\n",
    "credential = DefaultAzureCredential(authority=AZURE_GOV_AUTHORITY)\n",
    "\n",
    "# For interactive authentication (uncomment if needed):\n",
    "# credential = InteractiveBrowserCredential(authority=AZURE_GOV_AUTHORITY)\n",
    "\n",
    "# Azure Government SQL Database resource endpoint\n",
    "SQL_RESOURCE = \"https://database.usgovcloudapi.net/.default\"\n",
    "\n",
    "def get_sql_access_token():\n",
    "    \"\"\"Get an access token for Azure SQL Database authentication (Azure Government).\"\"\"\n",
    "    token = credential.get_token(SQL_RESOURCE)\n",
    "    # Format token for pyodbc\n",
    "    token_bytes = token.token.encode(\"UTF-16-LE\")\n",
    "    token_struct = struct.pack(f'<I{len(token_bytes)}s', len(token_bytes), token_bytes)\n",
    "    return token_struct\n",
    "\n",
    "print(\"✓ Credentials initialized for Azure Government Cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9831801",
   "metadata": {},
   "source": [
    "## 3. Connect to Synapse Workspace\n",
    "\n",
    "Access workspace artifacts like pipelines, datasets, linked services, and notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.synapse.artifacts import ArtifactsClient\n",
    "\n",
    "# Create the Artifacts client for workspace operations\n",
    "artifacts_client = ArtifactsClient(\n",
    "    credential=credential,\n",
    "    endpoint=SYNAPSE_DEV_ENDPOINT\n",
    ")\n",
    "\n",
    "# List linked services in the workspace\n",
    "print(\"Linked Services in workspace:\")\n",
    "print(\"-\" * 40)\n",
    "for ls in artifacts_client.linked_service.get_linked_services_by_workspace():\n",
    "    print(f\"  • {ls.name} ({ls.type})\")\n",
    "\n",
    "# List datasets\n",
    "print(\"\\nDatasets in workspace:\")\n",
    "print(\"-\" * 40)\n",
    "for ds in artifacts_client.dataset.get_datasets_by_workspace():\n",
    "    print(f\"  • {ds.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f0f305",
   "metadata": {},
   "source": [
    "## 4. Connect to Synapse SQL Databases\n",
    "\n",
    "### 4.1 Serverless SQL Pool (Built-in)\n",
    "\n",
    "Connect to the serverless SQL pool for on-demand queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "def get_synapse_connection(database: str, server: str = None) -> pyodbc.Connection:\n",
    "    \"\"\"\n",
    "    Create a connection to Synapse SQL using Azure AD authentication.\n",
    "    \n",
    "    Args:\n",
    "        database: The database name (use 'master' for serverless built-in)\n",
    "        server: The SQL endpoint (defaults to SYNAPSE_SQL_ENDPOINT)\n",
    "    \n",
    "    Returns:\n",
    "        pyodbc.Connection object\n",
    "    \"\"\"\n",
    "    server = server or SYNAPSE_SQL_ENDPOINT\n",
    "    \n",
    "    # Connection string for Azure AD token authentication\n",
    "    conn_str = (\n",
    "        f\"Driver={{ODBC Driver 18 for SQL Server}};\"\n",
    "        f\"Server={server};\"\n",
    "        f\"Database={database};\"\n",
    "        f\"Encrypt=yes;\"\n",
    "        f\"TrustServerCertificate=no;\"\n",
    "    )\n",
    "    \n",
    "    # Get access token and connect\n",
    "    token = get_sql_access_token()\n",
    "    conn = pyodbc.connect(conn_str, attrs_before={1256: token})\n",
    "    \n",
    "    return conn\n",
    "\n",
    "# Connect to Serverless SQL Pool (built-in)\n",
    "serverless_conn = get_synapse_connection(database=\"master\")\n",
    "print(\"✓ Connected to Serverless SQL Pool\")\n",
    "\n",
    "# List all databases\n",
    "query = \"SELECT name, database_id FROM sys.databases ORDER BY name\"\n",
    "df_databases = pd.read_sql(query, serverless_conn)\n",
    "print(\"\\nDatabases available:\")\n",
    "print(df_databases.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49c6f4c",
   "metadata": {},
   "source": [
    "### 4.2 Dedicated SQL Pool\n",
    "\n",
    "Connect to a provisioned dedicated SQL pool for data warehousing workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Dedicated SQL Pool\n",
    "dedicated_conn = get_synapse_connection(database=DEDICATED_SQL_POOL)\n",
    "print(f\"✓ Connected to Dedicated SQL Pool: {DEDICATED_SQL_POOL}\")\n",
    "\n",
    "# List schemas and tables in the dedicated pool\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    s.name AS schema_name,\n",
    "    t.name AS table_name,\n",
    "    p.rows AS row_count\n",
    "FROM sys.tables t\n",
    "INNER JOIN sys.schemas s ON t.schema_id = s.schema_id\n",
    "INNER JOIN sys.partitions p ON t.object_id = p.object_id AND p.index_id IN (0, 1)\n",
    "ORDER BY s.name, t.name\n",
    "\"\"\"\n",
    "df_tables = pd.read_sql(query, dedicated_conn)\n",
    "print(f\"\\nTables in {DEDICATED_SQL_POOL}:\")\n",
    "print(df_tables.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed962d9c",
   "metadata": {},
   "source": [
    "## 5. Connect to Lake Databases\n",
    "\n",
    "Lake databases in Synapse provide a metadata layer over data stored in Azure Data Lake Storage. You can query them via the serverless SQL pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4112e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to a Lake Database via Serverless SQL (on-demand endpoint)\n",
    "# Lake databases MUST use the serverless/on-demand endpoint\n",
    "lake_conn = get_synapse_connection(database=LAKE_DATABASE, server=SYNAPSE_SERVERLESS_ENDPOINT)\n",
    "print(f\"✓ Connected to Lake Database: {LAKE_DATABASE}\")\n",
    "\n",
    "# List tables in the Lake Database\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    s.name AS schema_name,\n",
    "    t.name AS table_name,\n",
    "    t.type_desc\n",
    "FROM sys.tables t\n",
    "INNER JOIN sys.schemas s ON t.schema_id = s.schema_id\n",
    "ORDER BY s.name, t.name\n",
    "\"\"\"\n",
    "df_lake_tables = pd.read_sql(query, lake_conn)\n",
    "print(f\"\\nTables in Lake Database '{LAKE_DATABASE}':\")\n",
    "print(df_lake_tables.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c86489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query data directly from Azure Data Lake using OPENROWSET\n",
    "# This works with Parquet, Delta, CSV, and JSON files\n",
    "\n",
    "query_parquet = f\"\"\"\n",
    "SELECT TOP 100 *\n",
    "FROM OPENROWSET(\n",
    "    BULK 'https://{ADLS_ACCOUNT}.dfs.core.windows.net/{ADLS_CONTAINER}/path/to/data/*.parquet',\n",
    "    FORMAT = 'PARQUET'\n",
    ") AS data\n",
    "\"\"\"\n",
    "\n",
    "# Query Delta Lake tables\n",
    "query_delta = f\"\"\"\n",
    "SELECT TOP 100 *\n",
    "FROM OPENROWSET(\n",
    "    BULK 'https://{ADLS_ACCOUNT}.dfs.core.windows.net/{ADLS_CONTAINER}/path/to/delta_table/',\n",
    "    FORMAT = 'DELTA'\n",
    ") AS data\n",
    "\"\"\"\n",
    "\n",
    "# Example: Run the parquet query (uncomment when paths are configured)\n",
    "# df_parquet = pd.read_sql(query_parquet, serverless_conn)\n",
    "# print(df_parquet.head())\n",
    "\n",
    "print(\"✓ OPENROWSET queries ready - update paths and uncomment to execute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c109dc",
   "metadata": {},
   "source": [
    "## 6. Query Linked Databases\n",
    "\n",
    "Access external databases through linked services configured in Synapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70559587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all linked services and their types\n",
    "print(\"Linked Services available for external database access:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for ls in artifacts_client.linked_service.get_linked_services_by_workspace():\n",
    "    ls_detail = artifacts_client.linked_service.get_linked_service(ls.name)\n",
    "    ls_type = ls_detail.properties.type if hasattr(ls_detail.properties, 'type') else 'Unknown'\n",
    "    print(f\"  • {ls.name}\")\n",
    "    print(f\"    Type: {ls_type}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query external SQL Server or Azure SQL via linked service\n",
    "# Using sp_execute_remote or three-part naming with external tables\n",
    "\n",
    "# Example: Create an external data source (run once in SQL)\n",
    "create_external_source = \"\"\"\n",
    "-- Run this in Synapse SQL to create external data source\n",
    "CREATE EXTERNAL DATA SOURCE LinkedAzureSQL\n",
    "WITH (\n",
    "    TYPE = RDBMS,\n",
    "    LOCATION = 'your-azure-sql-server.database.windows.net',\n",
    "    DATABASE_NAME = 'your_database',\n",
    "    CREDENTIAL = YourCredential\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Example: Query via external table\n",
    "query_external = \"\"\"\n",
    "-- Query external table (after creating external table definition)\n",
    "SELECT TOP 100 * \n",
    "FROM [ExternalSchema].[ExternalTable]\n",
    "\"\"\"\n",
    "\n",
    "# Example: Using three-part naming for linked databases\n",
    "query_linked = \"\"\"\n",
    "-- For databases linked via Synapse Link or external tables\n",
    "SELECT *\n",
    "FROM [LinkedDatabase].[schema].[table]\n",
    "\"\"\"\n",
    "\n",
    "print(\"✓ External query templates ready\")\n",
    "print(\"  Configure external data sources and credentials in Synapse Studio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e83f1",
   "metadata": {},
   "source": [
    "## 7. Using SQLAlchemy for ORM-style Access\n",
    "\n",
    "SQLAlchemy provides a more Pythonic interface for database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine import URL\n",
    "\n",
    "def create_synapse_engine(database: str, server: str = None):\n",
    "    \"\"\"\n",
    "    Create a SQLAlchemy engine for Synapse SQL with Azure AD authentication.\n",
    "    \n",
    "    Args:\n",
    "        database: The database name\n",
    "        server: The SQL endpoint (defaults to SYNAPSE_SQL_ENDPOINT)\n",
    "    \n",
    "    Returns:\n",
    "        SQLAlchemy Engine object\n",
    "    \"\"\"\n",
    "    server = server or SYNAPSE_SQL_ENDPOINT\n",
    "    \n",
    "    # Build connection URL\n",
    "    connection_url = URL.create(\n",
    "        \"mssql+pyodbc\",\n",
    "        query={\n",
    "            \"driver\": \"ODBC Driver 18 for SQL Server\",\n",
    "            \"Encrypt\": \"yes\",\n",
    "            \"TrustServerCertificate\": \"no\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Create engine with token-based authentication\n",
    "    def get_conn():\n",
    "        return get_synapse_connection(database, server)\n",
    "    \n",
    "    engine = create_engine(\n",
    "        f\"mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+18+for+SQL+Server&Encrypt=yes\",\n",
    "        creator=get_conn\n",
    "    )\n",
    "    \n",
    "    return engine\n",
    "\n",
    "# Create engine for serverless pool\n",
    "engine = create_synapse_engine(\"master\")\n",
    "\n",
    "# Test the connection\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT @@VERSION AS version\"))\n",
    "    version = result.fetchone()\n",
    "    print(f\"✓ SQLAlchemy connection successful\")\n",
    "    print(f\"  SQL Server Version: {version[0][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3ef75",
   "metadata": {},
   "source": [
    "## 8. Synapse Management Operations\n",
    "\n",
    "Use the Azure Management SDK to manage Synapse resources programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c74fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.mgmt.synapse import SynapseManagementClient\n",
    "from azure.identity import DefaultAzureCredential, AzureAuthorityHosts\n",
    "\n",
    "# Azure Government management endpoint\n",
    "AZURE_GOV_MGMT_URL = \"https://management.usgovcloudapi.net\"\n",
    "\n",
    "# Create a credential specifically for Azure Government management API\n",
    "# Need to get token with correct audience/scope\n",
    "mgmt_credential = DefaultAzureCredential(\n",
    "    authority=AzureAuthorityHosts.AZURE_GOVERNMENT,\n",
    "    exclude_shared_token_cache_credential=True\n",
    ")\n",
    "\n",
    "# Create management client for Azure Government\n",
    "mgmt_client = SynapseManagementClient(\n",
    "    credential=mgmt_credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    base_url=AZURE_GOV_MGMT_URL,\n",
    "    credential_scopes=[\"https://management.usgovcloudapi.net/.default\"]\n",
    ")\n",
    "\n",
    "# List SQL pools in the workspace\n",
    "print(f\"SQL Pools in workspace '{SYNAPSE_WORKSPACE_NAME}':\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# List Dedicated SQL Pools\n",
    "for pool in mgmt_client.sql_pools.list_by_workspace(RESOURCE_GROUP, SYNAPSE_WORKSPACE_NAME):\n",
    "    print(f\"  • {pool.name}\")\n",
    "    print(f\"    SKU: {pool.sku.name if pool.sku else 'N/A'}\")\n",
    "    print(f\"    Status: {pool.status}\")\n",
    "    print()\n",
    "\n",
    "# Get workspace details\n",
    "workspace = mgmt_client.workspaces.get(RESOURCE_GROUP, SYNAPSE_WORKSPACE_NAME)\n",
    "print(f\"Workspace Details:\")\n",
    "print(f\"  Name: {workspace.name}\")\n",
    "print(f\"  Location: {workspace.location}\")\n",
    "print(f\"  SQL Admin: {workspace.sql_administrator_login}\")\n",
    "print(f\"  Dev Endpoint: {workspace.connectivity_endpoints.get('dev', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4d1f78",
   "metadata": {},
   "source": [
    "## 9. Helper Functions\n",
    "\n",
    "Utility functions for common database operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_all_databases(conn: pyodbc.Connection) -> pd.DataFrame:\n",
    "    \"\"\"List all databases in the Synapse workspace.\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        name,\n",
    "        database_id,\n",
    "        create_date,\n",
    "        collation_name\n",
    "    FROM sys.databases\n",
    "    ORDER BY name\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "def list_tables(conn: pyodbc.Connection, schema: str = None) -> pd.DataFrame:\n",
    "    \"\"\"List all tables, optionally filtered by schema.\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        s.name AS schema_name,\n",
    "        t.name AS table_name,\n",
    "        t.type_desc,\n",
    "        t.create_date,\n",
    "        t.modify_date\n",
    "    FROM sys.tables t\n",
    "    INNER JOIN sys.schemas s ON t.schema_id = s.schema_id\n",
    "    \"\"\"\n",
    "    if schema:\n",
    "        query += f\" WHERE s.name = '{schema}'\"\n",
    "    query += \" ORDER BY s.name, t.name\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "def list_views(conn: pyodbc.Connection, schema: str = None) -> pd.DataFrame:\n",
    "    \"\"\"List all views, optionally filtered by schema.\"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        s.name AS schema_name,\n",
    "        v.name AS view_name,\n",
    "        v.create_date,\n",
    "        v.modify_date\n",
    "    FROM sys.views v\n",
    "    INNER JOIN sys.schemas s ON v.schema_id = s.schema_id\n",
    "    \"\"\"\n",
    "    if schema:\n",
    "        query += f\" WHERE s.name = '{schema}'\"\n",
    "    query += \" ORDER BY s.name, v.name\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "def get_table_columns(conn: pyodbc.Connection, table_name: str, schema: str = \"dbo\") -> pd.DataFrame:\n",
    "    \"\"\"Get column information for a specific table.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        c.name AS column_name,\n",
    "        t.name AS data_type,\n",
    "        c.max_length,\n",
    "        c.precision,\n",
    "        c.scale,\n",
    "        c.is_nullable,\n",
    "        c.is_identity\n",
    "    FROM sys.columns c\n",
    "    INNER JOIN sys.types t ON c.user_type_id = t.user_type_id\n",
    "    INNER JOIN sys.tables tbl ON c.object_id = tbl.object_id\n",
    "    INNER JOIN sys.schemas s ON tbl.schema_id = s.schema_id\n",
    "    WHERE tbl.name = '{table_name}' AND s.name = '{schema}'\n",
    "    ORDER BY c.column_id\n",
    "    \"\"\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "def run_query(conn: pyodbc.Connection, query: str) -> pd.DataFrame:\n",
    "    \"\"\"Execute a SQL query and return results as DataFrame.\"\"\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "print(\"✓ Helper functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db5a8e",
   "metadata": {},
   "source": [
    "## 10. Cleanup\n",
    "\n",
    "Close database connections when finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all connections\n",
    "connections_to_close = [\n",
    "    ('serverless_conn', 'Serverless SQL Pool'),\n",
    "    ('dedicated_conn', 'Dedicated SQL Pool'),\n",
    "    ('lake_conn', 'Lake Database'),\n",
    "]\n",
    "\n",
    "for conn_var, conn_name in connections_to_close:\n",
    "    if conn_var in dir() and locals().get(conn_var):\n",
    "        try:\n",
    "            locals()[conn_var].close()\n",
    "            print(f\"✓ Closed {conn_name} connection\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Error closing {conn_name}: {e}\")\n",
    "\n",
    "print(\"\\n✓ Cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
